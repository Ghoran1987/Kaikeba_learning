1.在实际工作中，FM和MF哪个应用的更多，为什么?
在实际工作中，FM比MF应用更多。MF是矩阵分解，在推荐系统的应用中，只能反映用户和物品之间单个特征维度的关系，无法反映多个特征特征维度之间的关系。
FM是分解机，其吸收了矩阵分解的思想，通过增加了二阶和高阶项，能够更好的拟合多特征之间的关系。因此，在多特征维度的推荐系统中，FM能够解决大规模稀疏数据中的特征组合问题，应用场景更广。
MF就是FM的一阶版本。
2.FFM与FM有哪些区别？
FM的本质就是利用矩阵分解的方式，降低模型的参数数量，解决稀疏矩阵中参数求解不精确的问题。与FM相比，FFM引入了field的概念，即对每个特征，其除了“特征index”以外，还有“field index”，这种操作使得FFM能够更好的捕捉到不同特征联合后对预测结果的贡献强度。
3.DeepFM相比于FM解决了哪些问题，原理是怎样的？
DeepFM解决了FM无法解决的高阶特征的挖掘问题。DeepFM是一个集成了FM和DNN的神经网络框架，类似于Google的Wide&Deep，Wide&Deep包括wide和deep两部分，其中wide部分是高维线性模型，DeepFM的wide部分则是FM模型；二者的deep部分都是dnn层。DNN隐藏层的激活函数用ReLu和Tanh，Sigmoid函数做CTR预估的输出函数。
4.Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？
baseline算法基于统计的基准预测线打分，通过建立一个对比基线，再将根据用户对物品进行打分和物品被打分的情况与基线进行评估，观察算法效果的提升。
BaselineOnly即给定用户和Item，给出基于baseline的估计值。
KNNBaseline考虑基线评级的协同过滤，即需要考虑到用户打分的偏差，基于baseline进行偏差计算。
5.基于邻域的协同过滤都有哪些算法，请简述原理？
一是KNNWithMeans算法，其基本的假设是用户和物品的评分有高低，考虑了每个用户打分均值或者每个item打分的均值，去除参考用户打分整体偏高和偏低的影响。
二是KNNBaseline算法，考虑到用户打分的偏差，偏差计算时基于baseline。
三是KNNWithZScore算法，考虑到了每个用户的归一化z分数，用以消除打分的偏差。