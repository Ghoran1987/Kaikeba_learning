1.XGBoost与GBDT的区别是什么？
xgboost属于GBDT模型的范畴，GBDT的基本想法是让新的基模型去拟合之前模型的偏差，从而不断将加法模型的偏差降低。相比于经典的GBDT，XGBoost做了一些改进，从而在效果和性能上有明显的提升。
第一，GBDT将目标函数泰勒展开到一阶，而XGBoost将目标函数泰勒展开到了二阶，能够保留更多有关目标函数的信息，对提升效果有帮助。
第二，GBDT是给新的基模型寻找新的拟合标签（前面加法模型的负梯度），而XGBoost是给新的基模型寻找新的目标函数（目标函数关于新的基模型的二阶泰勒展开）。
第三，XGBoost加入了和叶子权重的L2正则化项，因而有利于模型获得更低的方差。
第四，XGBoost增加了自动处理缺失值特征的策略。通过把带缺失值样本分别划分到左子树或者右子树，比较两种方案下目标函数的优劣，从而自动对有缺失值的样本进行划分，无需对缺失特征进行填充预处理。

2.举一个你之前做过的预测例子（用的什么模型，解决什么问题，比如我用LR模型，对员工离职进行了预测，效果如何... 请分享到课程微信群中）
在第三次课中，做了一个文本抄袭自动检测分析，用了多项式贝叶斯分类器，对文本的特征和Label进行训练，通过预测的Label值与实际的Label值进行比对，从而确定文本是否抄袭。
朴素贝叶斯的分类方法使用于小规模的数据，能够处理多分类任务，适合增量式训练。

3.请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度（鼓励分享到微信群中，进行交流）
以人脸识别为例，可以对人脸构建“眼睛、鼻子、耳朵、皮肤、头发”这个5个维度的特征，若要增加特征维度，可进一步划分出“眼睛形状、眼睛颜色、鼻子形状、耳朵大小、有无耳垂、皮肤颜色、毛孔特征、头发长短、颜色粗细”等更多特征，
特征越多，数据的维度就越大，模型就越复杂。